import 'dotenv/config';
import { OpenAI } from 'openai';

async function verifyWithGemini(history) {
    const geminiClient = new OpenAI({
        apiKey: process.env.GEMINI_API_KEY,
        baseURL: "https://generativelanguage.googleapis.com/v1beta/openai/"
    });

    const response = await geminiClient.chat.completions.create({
        model: 'gemini-2.0-flash',
        messages: history,
    });

    const choice = response.choices?.[0];
    const content = choice?.message?.content?.trim();

    if (content && content.length > 0) {
        return {
            success: true,
            content,
            meta: {
                id: response.id,
                model: response.model,
                finish_reason: choice?.finish_reason,
                usage: response.usage
            }
        };
    }

    return {
        success: false,
        error: "Gemini did not return any content.",
        meta: {
            id: response.id,
            model: response.model,
            finish_reason: choice?.finish_reason,
            usage: response.usage
        }
    };
}


const client = new OpenAI();

async function main() {
    // These API calls are stateless and can be made in parallel.
    // The client will handle rate limits and retries automatically.

    // Chain-of-thought
    // The model is guided to think through a problem step-by-step before arriving at a final answer.
    // This approach helps in breaking down complex problems and ensures a more thorough reasoning process.
    // LLM as a judge techinique is used to verify the thoughts of the primary LLM.
    // Here, Gemini is used as a secondary model to validate the reasoning steps of the primary model (OpenAI).
    // This helps in ensuring the accuracy and reliability of the responses generated by the primary model.
    const SYSTEM_PROMPT = `
        You are an AI assistant who works on START, THINK and OUTPUT format. For a given user query, you first START by acknowledging the query, then THINK by reasoning step-by-step about the best way to address the query, and finally OUTPUT the final answer. You should always keep thinking and thinking before giving the actual output.
        Also, before outputting the final answer to the user, you must check once if everything is correct.

        Rules:
        - Strictly follow the START, THINK, EVALUATE and OUTPUT format.
        - Strictly follow the output JSON format.
        - After every think, there is going to be a evaluate step that is performed manually by someone and you need to wait for that step to be completed before moving to next think or output step.
        - Always perform only one step at a time and wait for other step.
        - Always make sure to do multiple steps of thinking before giving out output.

        Output JSON format:
        {"step": "START/THINK/EVALUATE/OUTPUT", "content": "your content here"}

        Example:
        User: Can you solve 3 + 4 * 10 - 4 * 3
        Assistant: {"step": "START", "content": "Sure! Let's start by understanding the problem."}
        Assistant: {"step": "THINK", "content": "The user wants me to solve 3 + 4 * 10 - 4 * 3 maths problem."}
        Assistant: {"step": "EVALUATE", "content": "Alright, Going good so far. Please continue."}
        Assistant: {"step": "THINK", "content": "This is a typical math problem that involves addition, multiplication, and subtraction.This can be solved using the order of operations (PEMDAS/BODMAS)."}
        Assistant: {"step": "EVALUATE", "content": "Alright, Going good so far. Please continue."}
        Assistant: {"step": "THINK", "content": "Let's break down the problem step by step."}
        Assistant: {"step": "EVALUATE", "content": "Alright, Going good so far. Please continue."}
        Assistant: {"step": "THINK", "content": "First, we need to perform the multiplications: 4 * 10 = 40 and 4 * 3 = 12."}
        Assistant: {"step": "EVALUATE", "content": "Alright, Going good so far. Please continue."}
        Assistant: {"step": "THINK", "content": "Now we can rewrite the problem as: 3 + 40 - 12."}
        Assistant: {"step": "EVALUATE", "content": "Alright, Going good so far. Please continue."}
        Assistant: {"step": "THINK", "content": "Next, we need to perform the addition: 3 + 40 = 43."}
        Assistant: {"step": "EVALUATE", "content": "Alright, Going good so far. Please continue."}
        Assistant: {"step": "THINK", "content": "Finally, we need to perform the subtraction: 43 - 12 = 31."}
        Assistant: {"step": "EVALUATE", "content": "Alright, Going good so far. Please continue."}
        Assistant: {"step": "THINK", "content": "Let me double-check the calculations to ensure everything is correct."}
        Assistant: {"step": "EVALUATE", "content": "Alright, Going good so far. Please continue."}
        Assistant: {"step": "OUTPUT", "content": "The final answer to the problem 3 + 4 * 10 - 4 * 3 is 31."}
    `;
    const messages = [
        {
            role: 'system',
            content: SYSTEM_PROMPT,
        },
        {
            role: 'user',
            content: 'How to calculate the fibonacci sequence? Explain with an example.'
        }
    ];

    while (true) {
        const response = await client.chat.completions.create({
            model: 'gpt-4.1-mini',
            messages: messages,
        });
        const rawContent = response.choices[0].message.content;
        const parsedContent = JSON.parse(rawContent);

        if (parsedContent.step === 'START') {
            console.log(`Beginning: ${parsedContent.content}`);
            messages.push({ role: 'assistant', content: rawContent });
            continue;
        }
        else if (parsedContent.step === 'THINK') {
            console.log(`Thinking: ${parsedContent.content}`);

            const geminiHistory = [...messages, { role: 'assistant', content: rawContent }];
            const geminiResult = await verifyWithGemini(geminiHistory);
            if (geminiResult.success) {
                console.log("Gemini Verification Passed:", geminiResult.content);
            } else {
                console.error("Gemini Verification Failed:", geminiResult.error);
            }

            messages.push({ role: 'developer', content: JSON.stringify({ step: 'EVALUATE', content: 'Alright, Going good so far. Please continue.' }) });

            messages.push({ role: 'assistant', content: rawContent });
            continue;
        }
        else if (parsedContent.step === 'EVALUATE') {
            console.log(`Evaluating: ${parsedContent.content}`);
            messages.push({ role: 'assistant', content: rawContent });
            continue;
        }
        else if (parsedContent.step === 'OUTPUT') {
            console.log(`Output: ${parsedContent.content}`);
            messages.push({ role: 'assistant', content: rawContent });
            break;
        }
    }
}

main();